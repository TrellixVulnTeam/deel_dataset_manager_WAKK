{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitpytorchconda8fc07279373c45ea95d9df839de0f0c1",
   "display_name": "Python 3.7.6 64-bit ('pytorch': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from  functools import reduce\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# uncomment 2 lines below for local test\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.join(\"..\", \"..\"))\n",
    "\n",
    "from deel.datasets import load as load_dataset\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments for the script"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='VAE MVTEC Example')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=40, metavar='N',\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "parser.add_argument('--img-shape', type=tuple, default=(28,28))\n",
    "parser.add_argument('--analytic_kl', action='store_true')\n",
    "parser.add_argument('--h_dim', type=int, default=200)\n",
    "parser.add_argument('--z_dim', type=int, default=50)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "image_size = (3, 128, 128)\n",
    "loaders_kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "figsize = (16,8)\n",
    "\n",
    "main_class = 'bottle'\n",
    "other_ood_classes = ['screw', 'leather']\n",
    "\n",
    "z_size = 20\n",
    "\n",
    "# number of samples to produce or reconstruct\n",
    "num_samples = 16\n",
    "\n",
    "\n",
    "res_dir = 'results'\n",
    "if not os.path.isdir(res_dir):\n",
    "    os.makedirs(res_dir, exist_ok=True)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 'bottle' dataset from MVTec anomaly detection as ID and add 'screw' as other OOD "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset splits for PyTorch\n",
    "dataset = load_dataset(\n",
    "    \"mvtec-ad\",\n",
    "    mode=\"pytorch\",\n",
    "    split_by_class=True,\n",
    "    image_size=image_size[1:],\n",
    ")\n",
    "\n",
    "loader_ID_train = DataLoader(dataset[main_class]['train'][0], batch_size=args.batch_size, shuffle=True, **loaders_kwargs)\n",
    "loader_ID_valid = DataLoader(dataset[main_class]['test'][0], batch_size=args.batch_size, shuffle=False, **loaders_kwargs)\n",
    "loader_OOD      = DataLoader(dataset[main_class]['unknown'][0], batch_size=args.batch_size, shuffle=False, **loaders_kwargs)\n",
    "\n",
    "test_dataset_dict = {\n",
    "    'MVTEC ID train': loader_ID_train,\n",
    "    'MVTEC ID test': loader_ID_valid,\n",
    "    'MVTEC OOD': loader_OOD,\n",
    "}\n",
    "\n",
    "# Additional OOD dataset\n",
    "for cls in other_ood_classes:\n",
    "    test_dataset_dict['OOD_{}'.format(cls)] = DataLoader(\n",
    "        dataset[cls]['test'][0], \n",
    "        batch_size=args.batch_size, \n",
    "        shuffle=False, \n",
    "        **loaders_kwargs\n",
    "    )\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['bottle']\n",
    "#.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple VAE model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, img_size=(28,28), z_size=20, features=[400]):\n",
    "        super(VAE, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.input_size = reduce(lambda x,y: x*y, img_size)\n",
    "        self.z_size = z_size\n",
    "\n",
    "        features_in = [self.input_size] + features\n",
    "        features_out = features\n",
    "        layers = []\n",
    "        for f_in, f_out in zip(features_in, features_out):\n",
    "            layers.append(nn.Linear(f_in, f_out))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(*layers)\n",
    "\n",
    "        self.fc21 = nn.Linear(features[-1], self.z_size)\n",
    "        self.fc22 = nn.Linear(features[-1], self.z_size)\n",
    "\n",
    "        features_in = [z_size] + features[::-1]\n",
    "        features_out = features[::-1]\n",
    "        layers = []\n",
    "        for f_in, f_out in zip(features_in, features_out):\n",
    "            layers.append(nn.Linear(f_in, f_out))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.fc3 = nn.Sequential(*layers)\n",
    "\n",
    "        self.fc4 = nn.Linear(features[0], self.input_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.fc1(x)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3)).view(*((-1,) + self.img_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.input_size))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def sample(self, z):\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar, reduction='sum'):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction=reduction)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    if reduction == 'sum':\n",
    "       KLD = KLD.sum() \n",
    "    elif reduction == 'mean':\n",
    "       KLD = KLD.mean() \n",
    "\n",
    "    if reduction == 'none':\n",
    "       #print(reduction, 'BCE', BCE.shape, 'KLD', KLD.shape)\n",
    "       while len(BCE.shape) > 1:\n",
    "        BCE = BCE.sum(axis=1) \n",
    "       while len(KLD.shape) > 1:\n",
    "        KLD = KLD.sum(axis=1) \n",
    "\n",
    "    #print(reduction, 'BCE', BCE.shape, 'KLD', KLD.shape)\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train(epoch, loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loader.dataset),\n",
    "                100. * batch_idx / len(loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    train_loss /= len(loader.dataset)\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(epoch, res_dir=None, loader=loader_ID_valid):\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar, reduction='none')\n",
    "            test_losses.extend(loss.cpu().detach().numpy().tolist())\n",
    "            if i == 0 and res_dir:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         os.path.join(res_dir, 'reconstruction_{}.png'.format(epoch)), nrow=n)\n",
    "\n",
    "    test_loss = sum(test_losses) / len(test_losses)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n",
    "def reconstruct(label, res_dir=None, loader=loader_ID_valid):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            n = min(data.size(0), 8)\n",
    "            comparison = torch.cat([data[:n],\n",
    "                                    recon_batch[:n]\n",
    "                                    ])\n",
    "            save_image(comparison.cpu(),\n",
    "                        os.path.join(res_dir, 'reconstruction_{}.png'.format(label)), nrow=n)\n",
    "            break\n",
    "\n",
    "\n",
    "def eval(loader):\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar, reduction='none')\n",
    "            eval_loss.extend(loss.cpu().detach().numpy().tolist())\n",
    "    return eval_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VAE(image_size, z_size).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 10\n",
    "res_dir = 'results'\n",
    "ood_res_dir = os.path.join(res_dir, 'ood')\n",
    "\n",
    "for directory in [res_dir, ood_res_dir]:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "test_losses = {k:[] for k in test_dataset_dict}\n",
    "train_losses = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_losses.append(train(epoch, loader=loader_ID_train))\n",
    "    for k in test_losses: \n",
    "        test_losses[k].append(test(epoch, res_dir=None, loader=test_dataset_dict[k]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(*((num_samples,) + (z_size,))).to(device)\n",
    "        sample_dist = mods.path.join(res_dir, 'sample_{}.png'.format(epoch)))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='train')\n",
    "for label, losses in test_losses.items():\n",
    "    plt.plot(losses, label=label)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot losses "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=figsize)\n",
    "#plt.plot(train_losses, label='train')\n",
    "for label, losses in test_losses.items():\n",
    "    plt.plot(losses, label=label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do reconstruction on "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, loader in test_dataset_dict.items(): \n",
    "    ood_res_dir = os.path.join(res_dir, label)\n",
    "    if not os.path.isdir(ood_res_dir):\n",
    "        os.makedirs(ood_res_dir)\n",
    "    reconstruct(label, res_dir=ood_res_dir, loader=loader)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot evaluation histograms"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluations = {label: eval(loader) for  label,loader in test_dataset_dict.items()}\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "alpha_delta = 0.8\n",
    "alpha = 1.0\n",
    "for label, evaluation in evaluations.items():\n",
    "    weights = np.ones_like(evaluation)/float(len(evaluation))\n",
    "    plt.hist(evaluation, weights=weights, label=label, alpha=alpha)\n",
    "    alpha *= alpha_delta\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "alpha_delta = 0.8\n",
    "alpha = 1.0\n",
    "for label, evaluation in evaluations.items():\n",
    "    if \"MVTEC\" in label:\n",
    "        weights = np.ones_like(evaluation)/float(len(evaluation))\n",
    "        plt.hist(evaluation, weights=weights, label=label, alpha=alpha)\n",
    "        alpha *= alpha_delta\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}